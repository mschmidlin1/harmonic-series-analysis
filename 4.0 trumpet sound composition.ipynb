{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of the Harmonic Series in Trumpet Notes\n",
    "\n",
    "In music school we are taught that each note we play on an instrument not only sounds the fundamental frequency of that note, but also an entire series of overtones which contribute to how the note sounds. This is one component of the answer to the question \"Why does a violin sound different from a trumpet if they are playing the same pitch?\". In this report, we will examine and analyze the harmonic series in a single trumpet note. The purpose of this report is entirely educational, it gives me (a data scientist) the opportunity to practice using Fourier Transform and better understand the basics of signal processing. There are, however, a wide range of practical use cases for doing this type of analysis which I will mention throughout the report.\n",
    "\n",
    "\n",
    "This report will focus on three distinct areas:\n",
    "1. Frequency decomposition of a single trumpet note.\n",
    "2. Removal of frequencies in the trumpet note to understand the audio effect.\n",
    "3. Building synthetic trumpet notes using our acquired knowledge.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import IPython\n",
    "from scipy.signal import find_peaks\n",
    "import scipy\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Versions\n",
    "For anyone looking to follow along, here are all the relevant versions. This should allow you to recreate my environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"python: \", sys.version)\n",
    "print(\"numpy: \", np.__version__)\n",
    "print(\"matplotlib: \", matplotlib.__version__)\n",
    "print(\"librosa: \", librosa.__version__)\n",
    "print(\"IPython: \", IPython.__version__)\n",
    "print(\"scipy: \", scipy.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Loading and Basic Analysis\n",
    "\n",
    "Here we use the librosa library and import one of their example audio waveforms. This one is of a trumpet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.util.list_examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the trumpet clip\n",
    "filename = librosa.ex('trumpet')\n",
    "y, sr = librosa.load(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can listen to the trumpet clip by just pressing the play button!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the waveform of the audio clip. We will do this more than just once so we will define a function to create the plot for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_waveform(signal: np.ndarray, sample_rate: float) -> tuple:\n",
    "    \"\"\"\n",
    "    Plots an audio waveform with time on the x-axis.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    signal : np.ndarray\n",
    "        The input audio signal\n",
    "    sample_rate : float\n",
    "        The sampling rate of the signal in Hz\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        (fig, ax) - Matplotlib figure and axis objects for further customization\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> fig, ax = plot_waveform(y, sr)\n",
    "    >>> plt.show()\n",
    "    \"\"\"\n",
    "    # Create time array\n",
    "    duration = len(signal) / sample_rate\n",
    "    time = np.linspace(0, duration, len(signal))\n",
    "    \n",
    "    # Create plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "    \n",
    "    # Plot waveform\n",
    "    ax.plot(time, signal, 'b-', linewidth=0.5)\n",
    "    \n",
    "    # Customize plot\n",
    "    ax.set_xlabel('Time (seconds)')\n",
    "    ax.set_ylabel('Amplitude')\n",
    "    ax.set_title('Audio Waveform')\n",
    "    ax.grid(True)\n",
    "    \n",
    "    # Set y-axis limits with some padding\n",
    "    max_amp = np.max(np.abs(signal))\n",
    "    ax.set_ylim(-max_amp*1.1, max_amp*1.1)\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_waveform(y, sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are primarily interested in doing a more micro analysis of a single trumpet note so we will crop the data to get only the very first note."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = y[0:4000]\n",
    "fig, ax = plot_waveform(signal, sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can listen to it to make sure that we only got the first note and nothing else. If we got more then just the first note then we may have undesired frequencies in our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(data=signal, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency Decomposition with Fourier Analysis\n",
    "\n",
    "We want to examine the different frequencies that we have as a part of our single trumpet note. The best way to do this is a Fourier Transform. Fourier Transform is one of the essential tools used for signal analysis. It is able to decompose a signal into all the frequencies that make it up. We will use it for our analysis, however, we don't go into detail about how it actually works. If you would like to gain an intuitive understanding about how it works I suggest this video: https://www.youtube.com/watch?v=spUNpyF58BY\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Harmonic Series\n",
    "\n",
    "Now would also be a good time to give a little bit of background on the harmonic series. The harmonic series in *math* is defined as the infinite series formed by summing all positive unit fractions.\n",
    "\n",
    "$$\\sum_{n=1}^{\\infty} \\frac{1}{n} = 1 + \\frac{1}{2} + \\frac{1}{3} + \\frac{1}{4} + \\cdots$$\n",
    "\n",
    "The harmonic series in *music* is generally referred to as the sequence of integer multiples of some fundamental frequency where the fundamental is the perceived note. For example, if an instrument plays the note A you would hear the frequency of 440hz. However, baked into that note are also the pitches 440x2=880, 440x3=1320, 440x4=1760, etc...  These extra frequencies are part of what gives a particular note it's \"sound\". This is one of the fundamental things that gives each instrument it's own sound."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will define a helper function to perform the Fourier Transform and the plot the resulting frequency vs magnitude result. This will show us what the prominent frequencies in any signal are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_frequency_spectrum(signal: np.ndarray, sample_rate: float, return_peaks: bool = False) -> tuple:\n",
    "    \"\"\"\n",
    "    Analyzes and plots the frequency spectrum of an audio signal with peak detection\n",
    "    and musical note labeling. Optionally returns the list of peak frequencies.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    signal : np.ndarray\n",
    "        The input audio signal\n",
    "    sample_rate : float\n",
    "        The sampling rate of the signal in Hz\n",
    "    return_peaks : bool, optional\n",
    "        If True, returns the list of peak frequencies along with the plot\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        (fig, ax) - Matplotlib figure and axis objects for further customization\n",
    "        If return_peaks is True, also returns a list of peak frequencies\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> fig, ax = plot_frequency_spectrum(y, sr)\n",
    "    >>> plt.show()\n",
    "    >>> fig, ax, peaks = plot_frequency_spectrum(y, sr, return_peaks=True)\n",
    "    \"\"\"\n",
    "    # Compute FFT\n",
    "    n = len(signal)\n",
    "    fft_result = np.fft.fft(signal)\n",
    "    frequencies = np.fft.fftfreq(n, d=1/sample_rate)\n",
    "    \n",
    "    # Get positive frequencies\n",
    "    positive_frequencies = frequencies[:n//2]\n",
    "    magnitude_spectrum = np.abs(fft_result[:n//2])\n",
    "\n",
    "    # Find peaks with hard-coded parameters\n",
    "    peaks, _ = find_peaks(magnitude_spectrum, height= 2, distance=100)\n",
    "    peaks_frequency = positive_frequencies[peaks]\n",
    "    peaks_magnitude = magnitude_spectrum[peaks]\n",
    "\n",
    "    # Create plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    # Plot magnitude spectrum\n",
    "    ax.plot(positive_frequencies, magnitude_spectrum, marker='.')\n",
    "    \n",
    "    # Plot peaks\n",
    "    ax.plot(peaks_frequency, peaks_magnitude, \n",
    "            marker='x', color='red', linestyle='none')\n",
    "\n",
    "    # Add note labels for each peak\n",
    "    for freq, mag in zip(peaks_frequency, peaks_magnitude):\n",
    "        note = librosa.hz_to_note(freq)\n",
    "        ax.annotate(f'{note}={freq:.0f}Hz', \n",
    "                   xy=(freq, mag),  # Point to label\n",
    "                   xytext=(freq-1000, mag+2),  # Text position\n",
    "                   )\n",
    "\n",
    "    max_idx = np.argmax(magnitude_spectrum)\n",
    "    max_freq = positive_frequencies[max_idx]\n",
    "    fundemental_note = librosa.hz_to_note(max_freq)\n",
    "    ax.set_xlabel(\"Frequency (Hz)\")\n",
    "    ax.set_ylabel(\"Magnitude\")\n",
    "    ax.set_title(f\"Frequency Spectrum of trumpet note\")\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Adjust layout to prevent label clipping\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if return_peaks:\n",
    "        return fig, ax, peaks_frequency.tolist()\n",
    "    else:\n",
    "        return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax, peak_frequencies = plot_frequency_spectrum(signal, sr, return_peaks=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the resulting trumpet note is a D#(Eb). The fundamental (the note we hear) is Eb5, however, you can see very clearly in the plot we also have the frequencies D#6(Eb6), A#6(Bb6), D#7(Eb7), G7, A#7(Bb7), and C#8(Db8). After that it get's a bit more murky because the magnitudes get very small.\n",
    "\n",
    "This plot makes the hamonic series very aparent. Let's take the fundamental and multiply it by integers to really drive the point home.\n",
    "\n",
    "| Note | Frequency | Integer Multiple |\n",
    "|----------|----------|----------|\n",
    "| Eb    | 623     | x1     |\n",
    "| Eb    | 1246     | x2     |\n",
    "| Bb   | 1874     | x3     |\n",
    "| Eb    | 2497     | x4     |\n",
    "| G    | 3120     | x5     |\n",
    "| Bb    | 3743     | x6     |\n",
    "| Db    | 4371     | x7     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signal manipulation\n",
    "\n",
    "Now that we know this, we will see that the note sounds like if we deconstruct it's components. Mainly, we are interested in the contribution of the fundamental frequency vs all the harmonic overtones. Even though the fundamental is the pitch our ears hear, how much does it actually matter in the sound composition of the note?\n",
    "\n",
    "We will perform two exercies to figure this out. First we will remove all the frequencies except the fundamental. Second, we will remove only the fundamental. Then we can listen to the audio of both and see what matters more in terms of audio quality of the note.\n",
    "\n",
    "In order to do this, we will make three helper functions\n",
    "1. **reconstruct_frequency()** will take all the information needed to construct a cosine wave.\n",
    "2. **get_frequency_amplitude()** will use the Fourier Transform data and calculate the amplitude of the target frequency. This is done using the equation $amplitude = \\frac{2}{N} * magnitude$. The magnitude is what is plotted above in the Fourier Transform plot. N is the length of the signal. The reason we multiply by 2 is because we are only looking positive frequencies, while the Fourier Transform natively produces both positive and negative frequencies. We divide by N in order to normalize the amplitude to the length of the signal.\n",
    "3. **get_frequency_phase()** will use the Fourier Transform data and calculate the phase of the target frequency. This can be done by using the angle function in numpy which natively takes in the complex number from the Fourier Transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_frequency(frequency: float, \n",
    "                        time: np.ndarray, \n",
    "                        amplitude: float, \n",
    "                        phase: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Reconstructs a sinusoidal signal with specified frequency, amplitude, and phase.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    frequency : float\n",
    "        The frequency of the sinusoid in Hz.\n",
    "    time : np.ndarray\n",
    "        Time array in seconds.\n",
    "    amplitude : float\n",
    "        The amplitude of the sinusoid.\n",
    "    phase : float\n",
    "        The phase offset in radians.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        The reconstructed sinusoidal signal.\n",
    "    \"\"\"\n",
    "    return amplitude * np.cos(2 * np.pi * frequency * time + phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequency_amplitude(signal: np.ndarray, sample_rate: float, target_freq: float) -> float:\n",
    "    \"\"\"\n",
    "    Finds the amplitude of a signal at a specific frequency.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    signal : np.ndarray\n",
    "        The input signal to analyze.\n",
    "    sample_rate : float\n",
    "        The sampling rate of the signal in Hz.\n",
    "    target_freq : float\n",
    "        The frequency to analyze in Hz.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The amplitude of the signal at the target frequency.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If the target frequency is higher than the Nyquist frequency.\n",
    "        If the signal is empty or the sample rate is invalid.\n",
    "    \"\"\"\n",
    "    # Input validation\n",
    "    if not isinstance(signal, np.ndarray):\n",
    "        signal = np.array(signal)\n",
    "    \n",
    "    if len(signal) == 0:\n",
    "        raise ValueError(\"Signal cannot be empty\")\n",
    "    \n",
    "    if sample_rate <= 0:\n",
    "        raise ValueError(\"Sample rate must be positive\")\n",
    "    \n",
    "    nyquist = sample_rate / 2\n",
    "    if target_freq >= nyquist:\n",
    "        raise ValueError(f\"Target frequency ({target_freq} Hz) must be less than \"\n",
    "                       f\"Nyquist frequency ({nyquist} Hz)\")\n",
    "\n",
    "    # Compute FFT\n",
    "    N = len(signal)\n",
    "    Y = np.fft.fft(signal)\n",
    "    freqs = np.fft.fftfreq(N, 1/sample_rate)\n",
    "\n",
    "    # Find the index of the target frequency\n",
    "    freq_idx = np.argmin(np.abs(freqs - target_freq))\n",
    "    \n",
    "    # Get amplitude at target frequency\n",
    "    amplitude = 2.0/N * np.abs(Y[freq_idx])\n",
    "    \n",
    "    return amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequency_phase(signal: np.ndarray, sample_rate: float, target_freq: float) -> float:\n",
    "    \"\"\"\n",
    "    Finds the phase of a signal at a specific frequency.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    signal : np.ndarray\n",
    "        The input signal to analyze.\n",
    "    sample_rate : float\n",
    "        The sampling rate of the signal in Hz.\n",
    "    target_freq : float\n",
    "        The frequency to analyze in Hz.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The phase of the signal at the target frequency in radians.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If the target frequency is higher than the Nyquist frequency.\n",
    "        If the signal is empty or the sample rate is invalid.\n",
    "    \"\"\"\n",
    "    # Input validation\n",
    "    if not isinstance(signal, np.ndarray):\n",
    "        signal = np.array(signal)\n",
    "    \n",
    "    if len(signal) == 0:\n",
    "        raise ValueError(\"Signal cannot be empty\")\n",
    "    \n",
    "    if sample_rate <= 0:\n",
    "        raise ValueError(\"Sample rate must be positive\")\n",
    "    \n",
    "    nyquist = sample_rate / 2\n",
    "    if target_freq >= nyquist:\n",
    "        raise ValueError(f\"Target frequency ({target_freq} Hz) must be less than \"\n",
    "                       f\"Nyquist frequency ({nyquist} Hz)\")\n",
    "\n",
    "    # Compute FFT\n",
    "    N = len(signal)\n",
    "    Y = np.fft.fft(signal)\n",
    "    freqs = np.fft.fftfreq(N, 1/sample_rate)\n",
    "\n",
    "    # Find the index of the target frequency\n",
    "    freq_idx = np.argmin(np.abs(freqs - target_freq))\n",
    "    \n",
    "    # Get phase at target frequency\n",
    "    phase = np.angle(Y[freq_idx])\n",
    "    \n",
    "    return phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove all frequencies except the fundamental\n",
    "\n",
    "In order to do this we will iterate and remove all prominent frequencies except for the fundamental down to a certain threshold of magnitude. This threshold is currently set at 2 in the **plot_frequency_spectrum** function. This is necessary because there are many surrounding frequencies for each harmonic that must be removed in order to fully remove the sound of that harmonic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_seconds = np.arange(len(signal)) / sr #define the time array in seconds for use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "harmonics_removed = signal.copy()\n",
    "while True:\n",
    "    fig, ax, peak_frequencies = plot_frequency_spectrum(harmonics_removed, sr, return_peaks=True)\n",
    "    if len(peak_frequencies) == 1:\n",
    "        break\n",
    "    plt.close(fig)  # Close the figure to prevent display (except for the last iteration)\n",
    "    for freq in peak_frequencies:\n",
    "        if abs(freq - 622.9125) < 1:\n",
    "            continue\n",
    "        amplitude = get_frequency_amplitude(signal, sr, freq)\n",
    "        phase = get_frequency_phase(signal, sr, freq)\n",
    "        signal_freq = reconstruct_frequency(freq, time_seconds, amplitude, phase)\n",
    "        harmonics_removed = harmonics_removed - signal_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove only fundamental\n",
    "\n",
    "This is a similar process to removing all of the harmonics except this time we are removing the fundamental and all surrounding frequencies down to a threshold of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fundamental_removed = signal.copy()\n",
    "last_peak_frequencies = []\n",
    "while True:\n",
    "    fig, ax, peak_frequencies = plot_frequency_spectrum(fundamental_removed, sr, return_peaks=True)\n",
    "    if last_peak_frequencies == peak_frequencies:\n",
    "        break\n",
    "    last_peak_frequencies = peak_frequencies\n",
    "    plt.close(fig)  # Close the figure to prevent display\n",
    "    for freq in peak_frequencies:\n",
    "        if abs(freq - 622.9125) > 50:\n",
    "            continue\n",
    "        amplitude = get_frequency_amplitude(signal, sr, freq)\n",
    "        phase = get_frequency_phase(signal, sr, freq)\n",
    "        signal_freq = reconstruct_frequency(freq, time_seconds, amplitude, phase)\n",
    "        fundamental_removed = fundamental_removed - signal_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of Fundamental vs Harmonics\n",
    "\n",
    "Now just by listening to these clips we can hear how important the harmonics are to the sound signature of the note. The fundamental can be removed and the note still sounds relatively whole. If the harmonics are removed however leaving only the fundamental, it really doesn't sounds like a trumpet note at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(data=harmonics_removed, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(data=fundamental_removed, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Fundamental and Harmonics\n",
    "\n",
    "Now we will remove both the fundamental and the harmonics. The first reason for doing this is so that we can collect all the important signal data that makes up the trumpet note. The other reason is just for fun to see what the note sounds like if you remove all prominent frequencies.\n",
    "\n",
    "Note - in the field of signal processing I can image this could be very useful. If you have some signal and you want to clean any potential noise in it, you can deconstruct it into all of it's component frequencies and the filter out frequencies with an amplitude below some threshold. In the audio world this could potentially help do something like remove white noise or static."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_signals_removed = signal.copy()\n",
    "removed_signals = []\n",
    "removed_frequencies = []\n",
    "removed_amplitudes = []\n",
    "removed_phases = []\n",
    "while True:\n",
    "    fig, ax, peak_frequencies = plot_frequency_spectrum(all_signals_removed, sr, return_peaks=True)\n",
    "    if len(peak_frequencies) == 0:\n",
    "        break\n",
    "    plt.close(fig)  # Close the figure to prevent display\n",
    "    for freq in peak_frequencies:\n",
    "        amplitude = get_frequency_amplitude(signal, sr, freq)\n",
    "        phase = get_frequency_phase(signal, sr, freq)\n",
    "        signal_freq = reconstruct_frequency(freq, time_seconds, amplitude, phase)\n",
    "        removed_signals.append(signal_freq)\n",
    "        removed_frequencies.append(freq)\n",
    "        removed_amplitudes.append(amplitude)\n",
    "        removed_phases.append(phase)\n",
    "        all_signals_removed = all_signals_removed - signal_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It definitely doesn't sound like a trumpet anymore!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(data=all_signals_removed, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pitch shifting the original signal\n",
    "\n",
    "Now that we have extracted all the signal information we can try some things with it. First, we will just reassemble the signal and make sure it sounds good.\n",
    "\n",
    "\n",
    "Next, we will define a function which will help us shift the pitch by however many half steps (and whichever direction) we choose. It works based on the principle that to move an octave, you must double or halve your frequency. In 12-tone equal temperament (standard for most music), an octave is divided into 12 equally spaced pitches (semitones). Thus, to move a certain number of semitones, we can use the formula $f' = f \\times 2^{n/12}$, where $f$ is the original frequency and $n$ is the number of semitones to shift by.\n",
    "\n",
    "We can then use that function to create some major scales and see what they sound like.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert each list of np.float32 to python float\n",
    "removed_frequencies = [float(i) for i in removed_frequencies]\n",
    "removed_amplitudes = [float(i) for i in removed_amplitudes]\n",
    "removed_phases = [float(i) for i in removed_phases]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summed_signal = np.zeros(len(time_seconds))\n",
    "for freq, amp, phase in zip(removed_frequencies, removed_amplitudes, removed_phases):\n",
    "    reconstructed_signal = reconstruct_frequency(freq, time_seconds, amp, phase)\n",
    "    summed_signal += reconstructed_signal\n",
    "ipd.Audio(data=summed_signal, rate=sr) #reassembled pitch sounds good!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_pitch(frequency, semitones):\n",
    "    \"\"\"\n",
    "    Shifts the given frequency up or down by a specified number of semitones.\n",
    "\n",
    "    Parameters:\n",
    "        frequency (float): The original frequency in Hz.\n",
    "        semitones (int or float): Number of semitones to shift.\n",
    "                                  Positive for up, negative for down.\n",
    "\n",
    "    Returns:\n",
    "        float: The new frequency, shifted by the given number of semitones.\n",
    "    \"\"\"\n",
    "    semitone_ratio = 2 ** (1/12)\n",
    "    return frequency * (semitone_ratio ** semitones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "major_scale_down_shifts = [0, -1, -3, -5, -7, -8, -10, -12] #semi-tone shifts for a major scale\n",
    "scale_notes = []\n",
    "for shift_amount in major_scale_down_shifts:\n",
    "    summed_signal = np.zeros(len(time_seconds))\n",
    "    for freq, amp, phase in zip(removed_frequencies, removed_amplitudes, removed_phases):\n",
    "        reconstructed_signal = reconstruct_frequency(shift_pitch(freq, shift_amount), time_seconds, amp, phase)\n",
    "        summed_signal += reconstructed_signal\n",
    "    scale_notes.extend(list(summed_signal))\n",
    "\n",
    "ipd.Audio(data=scale_notes, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "major_scale_up_shifts = [0, 2, 4, 5, 7, 9, 11, 12] #semi-tone shifts for a major scale\n",
    "scale_notes = []\n",
    "for shift_amount in major_scale_up_shifts:\n",
    "    summed_signal = np.zeros(len(time_seconds))\n",
    "    for freq, amp, phase in zip(removed_frequencies, removed_amplitudes, removed_phases):\n",
    "        reconstructed_signal = reconstruct_frequency(shift_pitch(freq, shift_amount), time_seconds, amp, phase)\n",
    "        summed_signal += reconstructed_signal\n",
    "    scale_notes.extend(list(summed_signal))\n",
    "\n",
    "ipd.Audio(data=scale_notes, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can hear as you get farther away from the recorded pitch, the note stops sounding like a real trumpet. I think there are multiple reasons for this, the main one being that the amplitude of all the smaller frequencies surrounding each of the harmonics most likely would not work for other pitches as it gets farther away from the recorded pitch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate the sound of the trumpet\n",
    "\n",
    "In this section we wil try to simulate the sounds of the trumpet by learning from the recording and applying that to a compltely new and synthetic signal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of recorded frequencies\n",
    "\n",
    "First we must take a look at the recorded data so we know how to synthetically create our new signal.\n",
    "\n",
    "In order to do this we need to organize the frequency, phase, and amplitude data into their groupings for each harmonic. We can sort the three lists the same way and then bin the data on some threshold.\n",
    "\n",
    "Then, for each harmonic, we can look at the standard deviation of the frequencies, amplitudes, and phases. This will help us understand the relationship between the overtone series and all the frequencies that surround each overtone. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort all the frequencies, amplitudes, and phases by frequency and keep the order the same for each list\n",
    "sorted_freqs = sorted(removed_frequencies)\n",
    "sorted_amplitudes = sorted(removed_amplitudes, key = lambda amp: removed_frequencies[removed_amplitudes.index(amp)])\n",
    "sorted_phases = sorted(removed_phases, key = lambda phase: removed_frequencies[removed_phases.index(phase)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(removed_frequencies, bins=100); #it looks like a threshold of a couple hundred hz between each harmonic should work\n",
    "plt.xlabel(\"Frequency (Hz)\")\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.title(\"Histogram of frequncies for the trumpet note\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We learn 2 things from this histogram. The first is that a threshold of 200hz should be enough to seperate the harmonics. The second is that the distribution of the frequencies for each harmonic is normal-ish. It is shaped like the standard normal distribution but it is very narrow. This shape could be a contributing factor for why a trumpet sounds like a trumpet and not a violin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group the frequencies, amplitudes, and phases by the fundamental frequencies they had originally\n",
    "grouped_frequencies = []\n",
    "grouped_amplitudes = []\n",
    "grouped_phases = []\n",
    "current_freq_group = [sorted_freqs[0]]\n",
    "current_amp_group = [sorted_amplitudes[0]]\n",
    "current_phase_group = [sorted_phases[0]]\n",
    "\n",
    "\n",
    "for freq, amp, phase in zip(sorted_freqs[1:], sorted_amplitudes[1:], sorted_phases[1:]):\n",
    "    if freq - current_freq_group[-1] < 200:#200 is an arbitrary distance threshold between each group of frequencies\n",
    "        current_freq_group.append(freq)\n",
    "        current_amp_group.append(amp)\n",
    "        current_phase_group.append(phase)\n",
    "    else:\n",
    "        grouped_frequencies.append(current_freq_group)\n",
    "        grouped_amplitudes.append(current_amp_group)\n",
    "        grouped_phases.append(current_phase_group)\n",
    "        current_freq_group = [freq]\n",
    "        current_amp_group = [amp]\n",
    "        current_phase_group = [phase]\n",
    "grouped_frequencies.append(current_freq_group)\n",
    "grouped_amplitudes.append(current_amp_group)\n",
    "grouped_phases.append(current_phase_group)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_means = []\n",
    "freq_stdevs = []\n",
    "freq_counts = []\n",
    "for group in grouped_frequencies:\n",
    "    freq_means.append(int(np.mean(group)))\n",
    "    freq_stdevs.append(np.std(group))\n",
    "    freq_counts.append(len(group))\n",
    "plt.plot(freq_means,freq_stdevs)\n",
    "plt.xlabel(\"Frequency (Hz)\")\n",
    "plt.ylabel(\"Standard Deviation (Hz)\")\n",
    "plt.title(\"Standard Deviation of overtones at each harmonic\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation from *Standard Deviation of overtones at each harmonic*:\n",
    "- The standard deviation decreases as the harmonic increases. Is this because of higher pitch or a higher overtone, or both? We would need to study another trumpet pitch to find out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitude_means = []\n",
    "amplitude_stdevs = []\n",
    "amplitude_counts = []\n",
    "for group in grouped_amplitudes:\n",
    "    amplitude_means.append(np.mean(group))\n",
    "    amplitude_stdevs.append(np.std(group))\n",
    "    amplitude_counts.append(len(group))\n",
    "plt.plot(freq_means,amplitude_stdevs)\n",
    "plt.xlabel(\"Frequency (Hz)\")\n",
    "plt.ylabel(\"Standard Deviation of Amplitude\")\n",
    "plt.title(\"Standard Deviation of Amplitude at each harmonic\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation from *Standard Deviation of Amplitude at each harmonic*:\n",
    "- Standard deviation of amplitude decreases as the harmonic increases. This makes sense because the first few harmonics have a large outlier (the center pitch) which would significantly increase the standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_means = []\n",
    "phase_stdevs = []\n",
    "phase_counts = []\n",
    "for group in grouped_phases:\n",
    "    phase_means.append(np.mean(group))\n",
    "    phase_stdevs.append(np.std(group))\n",
    "    phase_counts.append(len(group))\n",
    "plt.plot(freq_means,phase_stdevs)\n",
    "plt.xlabel(\"Frequency (Hz)\")\n",
    "plt.ylabel(\"Standard Deviation of Phase\")\n",
    "plt.title(\"Standard Deviation of Phase at each harmonic\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation from *Standard Deviation of Phase at each harmonic*:\n",
    "- The trend still seems like it's going down however the slope is not significant compared to the overall movement over the harmonics. It seems unlikely there is a strong causal relationship here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_freq_0, group_phase_0 = grouped_frequencies[0], grouped_phases[0]\n",
    "len(group_freq_0), len(group_phase_0)\n",
    "plt.scatter(group_freq_0, group_phase_0)\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.ylabel(\"Phase\")\n",
    "plt.title(\"Frequency vs Phase for fundamental\")\n",
    "plt.show()#observation - phase seem fairly randomly distributed within one harmonic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation from *Frequency vs Phase for fundamental*:\n",
    "- There seems to be no pattern here. It is therefore reasonably safe to assume that for each harmonic, the distribution of phase is random inside the range [-3, 3]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_freq_0, group_amp_0  = grouped_frequencies[0], grouped_amplitudes[0]\n",
    "plt.scatter(group_freq_0, group_amp_0)\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.title(\"Frequency vs Amplitude for one harmonic\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation from *Frequency vs Amplitude for one harmonic*:\n",
    "- The amplitude is higher near the true frequency of the harmonic (as we can see in the FFT plots above).\n",
    "- The peak is so narrow and steep. In order to mimic this in a synthetic note we can probably just assign a large amplitude to the harmonic, then all the surrounding pitches can be the same amplitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_spreads = [max(freqs)-min(freqs) for freqs in grouped_frequencies] #get the range for each harmonics frequencies\n",
    "plt.scatter([h for h in range(8)], frequency_spreads)\n",
    "plt.xlabel(\"Harmonic (0 is fundamental)\")\n",
    "plt.ylabel(\"Range (Hz)\")\n",
    "plt.title(\"Spread of significant frequencies surrounding harmonic\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation from *Spread of significant frequencies surrounding harmonic*:\n",
    "- The range (max-min) of frequencies surrounding each harmonic seems to decrease as the partial increases. This makes sense since the standard deviation has the same trend.\n",
    "- We will arbitrarily generalize the below frequency spreads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_spreads = [250, 250, 250, 250, 200, 100, 50, 25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully synthetic note creation\n",
    "\n",
    "Now that we have studied the data of a real trumpet note we will try to generalize some of the things we learned in order to create a fake trumpet note.\n",
    "\n",
    "We will create one final function to calculate the harmonic series (up to the 7th partial) given some fundamental frequency. This will make it a little bit easier to create our synthetic note.\n",
    "\n",
    "Here are the steps we will take:\n",
    "1. Generate the harmonic series based off a chosen fundamental frequency. We know the hamornic series is key for reproducing the trumpet sound.\n",
    "2. Generate 10 lower frequencies on either side of each harmonic. The spread of the frequencies will be based on the one note we wave studied. We will use even spacing and give each frequency an amplitude of 0.002 for simplicity. At this point we can see the smaller frequencies surrounding each harmonic but we really don't understand what their contribution is to the sound of the note.\n",
    "3. For each frequency, we will randomly choose the phase on the range [-3, 3]. This is somewhat arbitrary as well. We know that the recorded note has approximately this range of phases and they seem random. However, we don't know what the impact of this is on the sound.\n",
    "4. Finally we will sum together all the signals and see what it sounds like. \n",
    "5. For good measure we can plot the Fourier Transform and make sure it looks as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_harmonic_series(fundamental_freq_hz: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculate the first 7 harmonics of the provided pitch.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    fundamental_freq_hz : float\n",
    "        The fundamental frequency in Hertz for which the overtones are to be calculated.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    np.ndarray\n",
    "        An array of frequencies representing the overtones of the given fundamental frequency. The fundamental is included as the first element of the array.\n",
    "    \"\"\"\n",
    "    factors = np.array([1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0])\n",
    "    return fundamental_freq_hz * factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "harmonic_amplitudes = []\n",
    "for amps in grouped_amplitudes:\n",
    "    harmonic_amplitudes.append(max(amps))\n",
    "harmonic_amplitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_harmonic_amplitude = 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "harmonic_series = get_harmonic_series(623)\n",
    "time_seconds = np.linspace(0, 1, sr) #1 second of audio at sr of 16000\n",
    "summed_signal = np.zeros(len(time_seconds))\n",
    "for i in range(len(harmonic_series)):\n",
    "    base_freq = harmonic_series[i] #this is the frequency of the base note of whatever harmonic we are on\n",
    "    base_amplitude = harmonic_amplitudes[i]\n",
    "    freq_spread = frequency_spreads[i]\n",
    "    half_spread = freq_spread/2\n",
    "    non_harmonic_frequencies = list(np.linspace(base_freq-half_spread, base_freq, 10, endpoint=False))\n",
    "    non_harmonic_frequencies.extend(list(np.linspace(base_freq+half_spread, base_freq, 10, endpoint=False)))\n",
    "\n",
    "    #create and add harmonic signal\n",
    "    summed_signal += reconstruct_frequency(base_freq, time_seconds, base_amplitude, np.random.uniform(-3, 3))\n",
    "\n",
    "    #create and add non-harmonic signals\n",
    "    for non_harmonic_freq in non_harmonic_frequencies:\n",
    "        summed_signal += reconstruct_frequency(non_harmonic_freq, time_seconds, non_harmonic_amplitude, np.random.uniform(-3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(data=summed_signal, rate=sr)#does not sound as expected!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax, peak_frequencies = plot_frequency_spectrum(summed_signal, sr, return_peaks=True) #looks as expected!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can hear, this really does not sound that much like a trumpet. It has some of the elements but clearly our simplistic way of creating the note does not capture the complexity of a real musical instrument. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "\n",
    "Through study and deconstruction of a single note we have seen the harmonic series and shows how important it is to the sound of a trumpet. We have practiced the basics of signal processing including Fourier Transform how we can reproduce or subtract frequencies from a signal. Finally, we have studied the relationships between the harmonic overtones and frequency, phase, and amplitude. We tried (and mostly failed) to create a synthetic trumpet note.\n",
    "\n",
    "\n",
    "Finally, here are some follow up tasks that could be pursued to take this exercise further:\n",
    "- Study other trumpet pitches to see which of the relationships in frequency, phase, and amplitude hold up.\n",
    "- Study other trumpet recordings to see which of the relationships in frequency, phase, and amplitude hold up.\n",
    "- Take these learnings and create a more sophisticated algorithm for creation of trumpet notes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
